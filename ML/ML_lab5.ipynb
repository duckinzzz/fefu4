{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:38.193805Z",
     "start_time": "2025-12-05T03:27:33.045644Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    print('GPU ok')\n",
    "else:\n",
    "    print('GPU not ok, CPU')"
   ],
   "id": "141d64ff6218866d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU ok\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:39.082146Z",
     "start_time": "2025-12-05T03:27:38.443919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"dialogues.tsv\", sep=\"\\t\")"
   ],
   "id": "29cc289fed08ee39",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:39.113980Z",
     "start_time": "2025-12-05T03:27:39.094830Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def clean_text_simple(text):\n",
    "    if not text:\n",
    "        return []\n",
    "\n",
    "    text = text.lower().replace(\"<br />\", \" \")\n",
    "    text = re.sub(r\"<span class=participant_\\d+>\", \"\", text)\n",
    "    msgs = text.split(\"</span> \")\n",
    "\n",
    "    replics = []\n",
    "\n",
    "    for message in msgs:\n",
    "        user_id = None\n",
    "        if 'пользователь 1: ' in message:\n",
    "            message = message.replace('пользователь 1: ', '')\n",
    "            user_id = 1\n",
    "        elif 'пользователь 2: ' in message:\n",
    "            message = message.replace('пользователь 2: ', '')\n",
    "            user_id = 2\n",
    "\n",
    "        if user_id is not None:\n",
    "            message = re.sub(r\"(?<=[a-zA-Zа-яА-ЯёЁ])[^a-zA-Zа-яА-ЯёЁ ](?=[a-zA-Zа-яА-ЯёЁ])\", \" \", message)\n",
    "            message = re.sub(r\"[^a-zA-Zа-яА-ЯёЁ ]+\", \" \", message)\n",
    "            message = re.sub(r\"\\s+\", \" \", message)\n",
    "            message = message.strip()\n",
    "            if message: replics.append([user_id, message])\n",
    "\n",
    "    return replics\n",
    "\n",
    "\n",
    "def merge_consecutive_replicas(replics):\n",
    "    if not replics:\n",
    "        return []\n",
    "\n",
    "    merged = []\n",
    "    current_user, current_msg = replics[0]\n",
    "\n",
    "    for user_id, msg in replics[1:]:\n",
    "        if user_id == current_user:\n",
    "            current_msg += \" \" + msg\n",
    "        else:\n",
    "            merged.append(current_msg.strip())\n",
    "            current_user, current_msg = user_id, msg\n",
    "\n",
    "    merged.append(current_msg.strip())\n",
    "    return merged"
   ],
   "id": "50f3035260a64048",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:41.178348Z",
     "start_time": "2025-12-05T03:27:39.117115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "pairs = []\n",
    "\n",
    "min_repl_len = 2\n",
    "max_repl_len = 40\n",
    "\n",
    "for d in df[\"dialogue\"]:\n",
    "    reps = clean_text_simple(d)\n",
    "    reps = merge_consecutive_replicas(reps)\n",
    "    for i in range(len(reps) - 1):\n",
    "        q = reps[i].strip()\n",
    "        a = reps[i + 1].strip()\n",
    "        if min_repl_len <= len(q.split()) <= max_repl_len and min_repl_len <= len(a.split()) <= max_repl_len:\n",
    "            pairs.append((q, a))\n"
   ],
   "id": "6fe5298a0ab7b9c2",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:44.125225Z",
     "start_time": "2025-12-05T03:27:44.109218Z"
    }
   },
   "cell_type": "code",
   "source": "len(pairs)",
   "id": "5d7fd990c61089ba",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130884"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:45.067169Z",
     "start_time": "2025-12-05T03:27:44.194840Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "all_reps = list(chain.from_iterable(pairs))\n",
    "\n",
    "lengths = [len(r.split()) for r in all_reps]\n",
    "\n",
    "print(\"Всего реплик:\", len(all_reps))\n",
    "print(\"Средняя длина:\", np.mean(lengths))\n",
    "print(\"Медиана длины:\", np.median(lengths))\n",
    "print(\"Максимальная длина:\", np.max(lengths))\n",
    "print(\"Минимальная длина:\", np.min(lengths))\n",
    "\n",
    "hist = Counter(lengths)\n",
    "print(\"\\nТоп частот длин:\")\n",
    "for length, freq in hist.most_common(20):\n",
    "    print(length, freq)\n",
    "\n",
    "all_tokens = list(chain.from_iterable(r.split() for r in all_reps))\n",
    "vocab = Counter(all_tokens)\n",
    "\n",
    "print(\"\\nРазмер словаря:\", len(vocab))\n",
    "print(\"Топ-20 самых частых слов:\")\n",
    "for tok, freq in vocab.most_common(20):\n",
    "    print(tok, freq)\n",
    "\n",
    "print(\"\\nПримеры редких слов (встречаются 1 раз):\")\n",
    "for tok, freq in list(vocab.items())[:20]:\n",
    "    if freq == 1:\n",
    "        print(tok)\n"
   ],
   "id": "ae91f7e106e9c6b5",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего реплик: 261768\n",
      "Средняя длина: 9.505810488676996\n",
      "Медиана длины: 7.0\n",
      "Максимальная длина: 40\n",
      "Минимальная длина: 2\n",
      "\n",
      "Топ частот длин:\n",
      "3 25912\n",
      "4 25760\n",
      "5 22893\n",
      "6 20376\n",
      "2 20175\n",
      "7 17539\n",
      "8 15461\n",
      "9 13869\n",
      "10 12447\n",
      "11 10818\n",
      "12 9781\n",
      "13 8335\n",
      "14 7484\n",
      "15 6539\n",
      "16 5781\n",
      "17 4913\n",
      "18 4296\n",
      "19 3817\n",
      "20 3237\n",
      "21 2864\n",
      "\n",
      "Размер словаря: 55695\n",
      "Топ-20 самых частых слов:\n",
      "я 109454\n",
      "а 87588\n",
      "в 57041\n",
      "у 54465\n",
      "и 48962\n",
      "не 42013\n",
      "люблю 41881\n",
      "ты 41844\n",
      "на 35452\n",
      "меня 34204\n",
      "как 28188\n",
      "есть 26994\n",
      "с 25803\n",
      "очень 23765\n",
      "это 23075\n",
      "тебя 22111\n",
      "что 22064\n",
      "да 21910\n",
      "но 18919\n",
      "чем 18287\n",
      "\n",
      "Примеры редких слов (встречаются 1 раз):\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:46.059205Z",
     "start_time": "2025-12-05T03:27:45.513365Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "q_lengths = [len(q.split()) for q, a in pairs]\n",
    "a_lengths = [len(a.split()) for q, a in pairs]\n",
    "\n",
    "all_lengths = q_lengths + a_lengths\n",
    "\n",
    "print(\"Всего пар:\", len(pairs))\n",
    "print(\"Средняя длина вопроса:\", np.mean(q_lengths))\n",
    "print(\"Средняя длина ответа:\", np.mean(a_lengths))\n",
    "print(\"Минимальная длина:\", np.min(all_lengths))\n",
    "print(\"Максимальная длина:\", np.max(all_lengths))\n",
    "print(\"Медиана длины:\", np.median(all_lengths))\n",
    "\n",
    "# распределение длин\n",
    "hist = Counter(all_lengths)\n",
    "print(\"\\nТоп частот длин:\")\n",
    "for length, freq in hist.most_common(20):\n",
    "    print(length, freq)\n",
    "\n",
    "short_pairs = sum(1 for q, a in pairs if len(q.split()) <= min_repl_len or len(a.split()) <= min_repl_len)\n",
    "long_pairs = sum(1 for q, a in pairs if len(q.split()) > max_repl_len or len(a.split()) > max_repl_len)\n",
    "\n",
    "print(\"\\nКоротких пар:\", short_pairs)\n",
    "print(\"Длинных пар:\", long_pairs)\n",
    "print(\"Доля коротких:\", short_pairs / len(pairs))\n",
    "print(\"Доля длинных:\", long_pairs / len(pairs))\n"
   ],
   "id": "19957ee57ade4398",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего пар: 130884\n",
      "Средняя длина вопроса: 9.342578160814156\n",
      "Средняя длина ответа: 9.669042816539838\n",
      "Минимальная длина: 2\n",
      "Максимальная длина: 40\n",
      "Медиана длины: 7.0\n",
      "\n",
      "Топ частот длин:\n",
      "3 25912\n",
      "4 25760\n",
      "5 22893\n",
      "6 20376\n",
      "2 20175\n",
      "7 17539\n",
      "8 15461\n",
      "9 13869\n",
      "10 12447\n",
      "11 10818\n",
      "12 9781\n",
      "13 8335\n",
      "14 7484\n",
      "15 6539\n",
      "16 5781\n",
      "17 4913\n",
      "18 4296\n",
      "19 3817\n",
      "20 3237\n",
      "21 2864\n",
      "\n",
      "Коротких пар: 18862\n",
      "Длинных пар: 0\n",
      "Доля коротких: 0.14411234375477522\n",
      "Доля длинных: 0.0\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:54.109799Z",
     "start_time": "2025-12-05T03:27:46.431799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "\n",
    "questions, answers = zip(*pairs)\n",
    "\n",
    "min_num_words = 8000\n",
    "\n",
    "tokenizer = Tokenizer(num_words=min_num_words, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(questions + answers)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "vocab_size = min(min_num_words, len(word_index)) + 1\n",
    "\n",
    "questions_seq = tokenizer.texts_to_sequences(questions)\n",
    "answers_seq = tokenizer.texts_to_sequences(answers)\n",
    "\n",
    "max_len = max(max(len(seq) for seq in questions_seq),\n",
    "              max(len(seq) for seq in answers_seq))\n",
    "\n",
    "questions_pad = pad_sequences(questions_seq, maxlen=max_len, padding='post')\n",
    "answers_pad = pad_sequences(answers_seq, maxlen=max_len, padding='post')\n",
    "\n",
    "decoder_input = answers_pad[:, :-1]\n",
    "decoder_target = answers_pad[:, 1:]\n",
    "\n",
    "print(\"Размер словаря:\", vocab_size)\n",
    "print(\"Максимальная длина последовательности:\", max_len)\n",
    "print(\"Форма входных данных:\", questions_pad.shape, decoder_input.shape, decoder_target.shape)\n"
   ],
   "id": "7723eb90fbf1c92a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря: 8001\n",
      "Максимальная длина последовательности: 40\n",
      "Форма входных данных: (130884, 40) (130884, 39) (130884, 39)\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:27:57.283591Z",
     "start_time": "2025-12-05T03:27:54.472831Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, AdditiveAttention, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "embedding_dim = 128\n",
    "latent_dim = 128\n",
    "\n",
    "encoder_inputs = Input(shape=(max_len,), name='encoder_inputs')\n",
    "encoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True, name='encoder_embedding')(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='encoder_lstm')\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_inputs = Input(shape=(max_len - 1,), name='decoder_inputs')\n",
    "decoder_embedding = Embedding(input_dim=vocab_size, output_dim=embedding_dim, mask_zero=True, name='decoder_embedding')(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True, name='decoder_lstm')\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "\n",
    "attention = AdditiveAttention(name='attention_layer')\n",
    "context_vector = attention([decoder_outputs, encoder_outputs])\n",
    "decoder_combined = Concatenate(axis=-1)([decoder_outputs, context_vector])\n",
    "\n",
    "decoder_dense = Dense(vocab_size, activation='softmax', name='decoder_dense')\n",
    "decoder_outputs = decoder_dense(decoder_combined)\n",
    "\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs, name='seq2seq_attention')\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ],
   "id": "745d423bacd73be1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"seq2seq_attention\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " encoder_inputs (InputLayer)    [(None, 40)]         0           []                               \n",
      "                                                                                                  \n",
      " decoder_inputs (InputLayer)    [(None, 39)]         0           []                               \n",
      "                                                                                                  \n",
      " encoder_embedding (Embedding)  (None, 40, 128)      1024128     ['encoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " decoder_embedding (Embedding)  (None, 39, 128)      1024128     ['decoder_inputs[0][0]']         \n",
      "                                                                                                  \n",
      " encoder_lstm (LSTM)            [(None, 40, 128),    131584      ['encoder_embedding[0][0]']      \n",
      "                                 (None, 128),                                                     \n",
      "                                 (None, 128)]                                                     \n",
      "                                                                                                  \n",
      " decoder_lstm (LSTM)            [(None, 39, 128),    131584      ['decoder_embedding[0][0]',      \n",
      "                                 (None, 128),                     'encoder_lstm[0][1]',           \n",
      "                                 (None, 128)]                     'encoder_lstm[0][2]']           \n",
      "                                                                                                  \n",
      " attention_layer (AdditiveAtten  (None, 39, 128)     128         ['decoder_lstm[0][0]',           \n",
      " tion)                                                            'encoder_lstm[0][0]']           \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 39, 256)      0           ['decoder_lstm[0][0]',           \n",
      "                                                                  'attention_layer[0][0]']        \n",
      "                                                                                                  \n",
      " decoder_dense (Dense)          (None, 39, 8001)     2056257     ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,367,809\n",
      "Trainable params: 4,367,809\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:07.711852Z",
     "start_time": "2025-12-05T03:27:57.719069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=1,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    [questions_pad, decoder_input],\n",
    "    decoder_target,\n",
    "    batch_size=128,\n",
    "    epochs=20,\n",
    "    validation_split=0.1,\n",
    "    callbacks=[early_stop]\n",
    ")\n"
   ],
   "id": "dc34a7ee1abdb82e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "921/921 [==============================] - 85s 79ms/step - loss: 1.4863 - accuracy: 0.1314 - val_loss: 1.4033 - val_accuracy: 0.1631\n",
      "Epoch 2/20\n",
      "921/921 [==============================] - 74s 81ms/step - loss: 1.3432 - accuracy: 0.1738 - val_loss: 1.3260 - val_accuracy: 0.1784\n",
      "Epoch 3/20\n",
      "921/921 [==============================] - 72s 78ms/step - loss: 1.2801 - accuracy: 0.1879 - val_loss: 1.2786 - val_accuracy: 0.1915\n",
      "Epoch 4/20\n",
      "921/921 [==============================] - 88s 96ms/step - loss: 1.2328 - accuracy: 0.2012 - val_loss: 1.2403 - val_accuracy: 0.2031\n",
      "Epoch 5/20\n",
      "921/921 [==============================] - 74s 80ms/step - loss: 1.1943 - accuracy: 0.2126 - val_loss: 1.2124 - val_accuracy: 0.2128\n",
      "Epoch 6/20\n",
      "921/921 [==============================] - 87s 94ms/step - loss: 1.1646 - accuracy: 0.2216 - val_loss: 1.1920 - val_accuracy: 0.2172\n",
      "Epoch 7/20\n",
      "921/921 [==============================] - 93s 101ms/step - loss: 1.1409 - accuracy: 0.2291 - val_loss: 1.1767 - val_accuracy: 0.2216\n",
      "Epoch 8/20\n",
      "921/921 [==============================] - 136s 148ms/step - loss: 1.1209 - accuracy: 0.2353 - val_loss: 1.1654 - val_accuracy: 0.2265\n",
      "Epoch 9/20\n",
      "921/921 [==============================] - 70s 76ms/step - loss: 1.1039 - accuracy: 0.2397 - val_loss: 1.1563 - val_accuracy: 0.2288\n",
      "Epoch 10/20\n",
      "921/921 [==============================] - 72s 78ms/step - loss: 1.0889 - accuracy: 0.2438 - val_loss: 1.1495 - val_accuracy: 0.2311\n",
      "Epoch 11/20\n",
      "921/921 [==============================] - 70s 76ms/step - loss: 1.0753 - accuracy: 0.2476 - val_loss: 1.1440 - val_accuracy: 0.2329\n",
      "Epoch 12/20\n",
      "921/921 [==============================] - 69s 75ms/step - loss: 1.0629 - accuracy: 0.2511 - val_loss: 1.1395 - val_accuracy: 0.2336\n",
      "Epoch 13/20\n",
      "921/921 [==============================] - 69s 75ms/step - loss: 1.0513 - accuracy: 0.2543 - val_loss: 1.1367 - val_accuracy: 0.2350\n",
      "Epoch 14/20\n",
      "921/921 [==============================] - 69s 75ms/step - loss: 1.0404 - accuracy: 0.2573 - val_loss: 1.1342 - val_accuracy: 0.2363\n",
      "Epoch 15/20\n",
      "921/921 [==============================] - 69s 75ms/step - loss: 1.0301 - accuracy: 0.2600 - val_loss: 1.1321 - val_accuracy: 0.2370\n",
      "Epoch 16/20\n",
      "921/921 [==============================] - 70s 76ms/step - loss: 1.0202 - accuracy: 0.2628 - val_loss: 1.1315 - val_accuracy: 0.2372\n",
      "Epoch 17/20\n",
      "921/921 [==============================] - 70s 76ms/step - loss: 1.0109 - accuracy: 0.2652 - val_loss: 1.1296 - val_accuracy: 0.2371\n",
      "Epoch 18/20\n",
      "921/921 [==============================] - 81s 88ms/step - loss: 1.0018 - accuracy: 0.2678 - val_loss: 1.1295 - val_accuracy: 0.2376\n",
      "Epoch 19/20\n",
      "921/921 [==============================] - 91s 99ms/step - loss: 0.9931 - accuracy: 0.2703 - val_loss: 1.1299 - val_accuracy: 0.2382\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:10.757740Z",
     "start_time": "2025-12-05T03:53:09.287358Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Concatenate\n",
    "\n",
    "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,), name='decoder_state_input_h')\n",
    "decoder_state_input_c = Input(shape=(latent_dim,), name='decoder_state_input_c')\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_inputs_single = Input(shape=(1,), name='decoder_inputs_single')\n",
    "decoder_embedding_layer = model.get_layer('decoder_embedding')\n",
    "decoder_embedded = decoder_embedding_layer(decoder_inputs_single)\n",
    "\n",
    "decoder_outputs2, state_h2, state_c2 = decoder_lstm(decoder_embedded, initial_state=decoder_states_inputs)\n",
    "decoder_states2 = [state_h2, state_c2]\n",
    "\n",
    "attention_layer = model.get_layer('attention_layer')\n",
    "context_vector = attention_layer([decoder_outputs2, encoder_outputs])\n",
    "decoder_combined = Concatenate(axis=-1)([decoder_outputs2, context_vector])\n",
    "\n",
    "decoder_outputs2 = decoder_dense(decoder_combined)\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs_single] + decoder_states_inputs + [encoder_outputs],\n",
    "    [decoder_outputs2] + decoder_states2\n",
    ")\n"
   ],
   "id": "17c9cd000b59dea7",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:10.787805Z",
     "start_time": "2025-12-05T03:53:10.757740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import heapq\n",
    "import numpy as np\n",
    "\n",
    "def beam_search_decode(input_seq, beam_width=3, max_response_len=7):\n",
    "    encoder_outs, state_h, state_c = encoder_model.predict(input_seq)\n",
    "    states_value = [state_h, state_c]\n",
    "    start_token = tokenizer.word_index.get('я', 1)\n",
    "\n",
    "    sequences = [(0.0, [start_token], states_value)]\n",
    "\n",
    "    for _ in range(max_response_len):\n",
    "        all_candidates = []\n",
    "        for score, seq, states in sequences:\n",
    "            target_seq = np.array([[seq[-1]]])\n",
    "            output_tokens, h, c = decoder_model.predict([target_seq] + states + [encoder_outs])\n",
    "\n",
    "            log_probs = np.log(output_tokens[0, -1, :] + 1e-8)\n",
    "            top_indices = np.argsort(log_probs)[-beam_width:]\n",
    "\n",
    "            for i in top_indices:\n",
    "                candidate = (score + log_probs[i], seq + [i], [h, c])\n",
    "                all_candidates.append(candidate)\n",
    "\n",
    "        sequences = heapq.nlargest(beam_width, all_candidates, key=lambda tup: tup[0])\n",
    "\n",
    "    best_seq = sequences[0][1]\n",
    "    decoded_sentence = []\n",
    "    for token_idx in best_seq[1:]:\n",
    "        word = tokenizer.index_word.get(token_idx, '')\n",
    "        if word == '' or word == '<OOV>':\n",
    "            continue\n",
    "        if decoded_sentence and word == decoded_sentence[-1]:\n",
    "            continue\n",
    "        decoded_sentence.append(word)\n",
    "\n",
    "    return ' '.join(decoded_sentence)\n"
   ],
   "id": "4286dd17088733d8",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:10.914652Z",
     "start_time": "2025-12-05T03:53:10.796221Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "user_input = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Напиши сообщение...',\n",
    "    description='Ты:',\n",
    "    layout=widgets.Layout(width='80%')\n",
    ")\n",
    "\n",
    "chat_output = widgets.Output(layout=widgets.Layout(width='80%', border='1px solid black', padding='5px'))\n",
    "\n",
    "send_button = widgets.Button(description=\"Отправить\")\n",
    "\n",
    "\n",
    "def on_send_clicked(b):\n",
    "    msg = user_input.value.strip()\n",
    "    if not msg:\n",
    "        return\n",
    "\n",
    "    with chat_output:\n",
    "        print(f\"Ты: {msg}\")\n",
    "\n",
    "    seq = pad_sequences(tokenizer.texts_to_sequences([msg]), maxlen=max_len, padding='post')\n",
    "    response = beam_search_decode(seq)\n",
    "\n",
    "    with chat_output:\n",
    "        print(f\"Бот: {response}\\n\")\n",
    "\n",
    "    user_input.value = ''\n",
    "\n",
    "\n",
    "send_button.on_click(on_send_clicked)\n",
    "\n",
    "display(chat_output, user_input, send_button)\n"
   ],
   "id": "af5665585237a8be",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Output(layout=Layout(border_bottom='1px solid black', border_left='1px solid black', border_right='1px solid b…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "33f71b4343e9482a920212a3732a8e13"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Text(value='', description='Ты:', layout=Layout(width='80%'), placeholder='Напиши сообщение...')"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "67e32d35a72d4e3eae1bab64342a6645"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "Button(description='Отправить', style=ButtonStyle())"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0eb2f25fe9a84c238d18c702d1df109b"
      }
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:11.045851Z",
     "start_time": "2025-12-05T03:53:10.951757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import datetime\n",
    "\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "encoder_model.save(f'checkpoints/{timestamp}_20epch/encoder_model.h5')\n",
    "decoder_model.save(f'checkpoints/{timestamp}_20epch/decoder_model.h5')\n"
   ],
   "id": "2f846e31f0b2cbb6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-05T03:53:11.070374Z",
     "start_time": "2025-12-05T03:53:11.058193Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "acc1ff2c6ae9854a",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
